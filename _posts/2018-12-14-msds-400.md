---
layout: post
mathjax: true
comments: true
title: Northwestern Data Science Series Part 1
---
## Math For Data Scientists
Hello, and thanks for reading!  This is the first part in a 12 part data science series.  This series is intended to chronicle my journey through the Data Science graduate program at Northwestern University.

Math for Data Scientists (MSDS-400) was the first class I completed in my Data Science graduate program.  The class was designed as a primer/refresher for foundational mathematical concepts used with various modeling techniques.

The core objectives for the class were:  
1. Apply linear programming methods to real world models.
2. Analyze and interpret mathematical models.
3. Create graphs and trees to model real world problems.
4. Calculate and analyze derivatives and integrals of real world models.
5. Evaluate and interpret probabilistic models.

The majority of the class was spent working on linear algebra and calculus.  We took a brief break between these two areas to study algorithms and graph theory.  I'll go into more detail on each of these pieces throughout this post.  Let's dive in!

### Apply Linear Programming Methods to Real World Models

#### Least Squares Line
We'll start out with a relatively basic review of linear functions.  One of the most basic predictive methods is the least squares line. The goal of the least squares line is to minimize the sum of the squares of the vertical distances from given data points (on a scatterplot) to the line itself.  Now what does this actually mean?  If you've ever worked in excel and chosen to fit a linear trend line to a scatterplot you've created, then you're already ahead of the game. We're essentially trying to find the line of best fit for a set of data points.  

Let's review a brief example.  The equation for the least squares line $Y=mx+b$ that gives the best fit to the data points $(x_{1},y_{1}), (x_{2},y_{2}),....(x_{n},y_{n})$ has slope $m$ and $y$-intercept $b$ is given by:  

$$
m=\frac{n(\sum xy)-(\sum x)(\sum y)}{n(\sum x^{2})-(\sum x)^{2}}
$$

$$
b=\frac{(\sum y)-m(\sum x)}{n}
$$

This mathematical notation can best be visualized with a small set of data points. We'll use the following table to calculate the least squares line.

| $x$ | $y$ | $xy$ | $x^2$ | $y^2$ |
|:---:|:---:|:----:|:-----:|:-----:|
| $20$  | $71.2$ | $1,424$ | $400$ | $5,069.44$ |
|$30$   | $80.5$  | $2,415$  | $900$  |$6,480.25$   |
|$40$   |$73.4$   |$2,936$   |$1,600$   |$5,387.56$   |
|$50$   |$60.3$   |$3,015$   |$2,500$   |$3,636.09$   |
|$60$   |$52.1$   |$3,126$   |$3,600$   |$2,714.41$   |
|$70$   |$56.2$   |$3,934$   |$4,900$   |$3,158.44$   |
|$80$   |$46.5$   |$3,720$   |$6,400$   |$2,162.25$   |
|$90$   |$36.9$   |$3,321$   |$8,100$   |$1,361.61$   |
|$100$   |$34.0$   |$3,400$   |$10,000$   |$1,156.00$   |
|$110$   |$39.1$   |$4,301$   |$12,100$   |$1,528.81$   |
|$\sum x = 650$   |$\sum y = 550.2$   |$\sum xy = 31,592$   |$\sum x^2 = 50,500$   |$\sum y^2 = 32,654.86$   |

If we plug the values from the table into our equation we get the following:

$$
m=\frac{10(31,592)-(650)(550.2)}{10(50,500)-(650)^2}
$$

$$
m=-0.506
$$

$$
b=\frac{550.2-(-0.506)(650)}{10}
$$

$$
b=87.9
$$

We now have the components for our least squares line represented by:

$$
Y=-0.506x+87.9
$$

This forms the basis for a very simple method of prediction.  If we are given values for $x$ we can predict $y$. Without knowing how well this line fits our data, we can't be sure our predictions will be accurate. To help us with this problem we turn to the correlation coefficient. The correlation coefficient is denoted by $r$ and is calculated using the following formula:

$$
r=\frac{n(\sum xy)-(\sum x)(\sum y)}{\sqrt{n(\sum x^2)-(\sum x)^2}\cdot \sqrt{n(\sum y^2)-(\sum y)^2}}
$$

The correlation coefficient measures the strength of the linear relationship between two variables and was developed by Karl Pearson (1857 - 1936). The coefficient always lies between $-1$ and $1$. Values of $1$ or $-1$ indicate that the data points lie exactly on the least squares line. A coefficient of $1$ represents a positive slope while $-1$ represents a negative slope.  If $r=0$, there is no linear correlation between the data points.  Continuing with our sample data above we can calculate the correlation coefficient:

$$
r=-0.936
$$

$$
r^2=0.876
$$

Our $r$ value indicates a strong negative correlation between our variables.  We observe the $r^2$ value of $0.876$ which represents the variation in $y$ that is explained by the linear relationship between $x$ and $y$. This means that approximately $87.6\%$ of the variation in $y$ is explained by the linear relationship. Even though we have a strong linear correlation, this does not always imply causation.  There are further techniques that can be applied that are outside the scope of this post.

#### Systems of Linear Equations
Moving on from the least squares line, we expand into solving systems of linear equations. Many mathematical models require finding the solution of two or more equations, and the solution must satisfy all of the equations of the model. This forms the basis for a **system of equations**.  In this section we'll review two different methods for solving these systems:
1. Echelon Method
2. Gauss-Jordan Method

##### Echelon Method
The Echelon Method is a systematic approach for solving systems of equations using the *three transformations of a system*. The three transformations are comprised of algebraic properties and can be defined as follows:
1. Exchanging any two equations
2. Multiplying both sides of an equation by any nonzero real number
3. Replacing any equation by a nonzero multiple of that equation plus a nonzero multiple of any other equation

The Echelon method can be thought of as an elimination method.  The elimination method allows for any variable to be eliminated. Once we're able to eliminate a variable, we can use *back substitution* to calculate the remaining variable. Let's look at a simplified example of this:

Let's solve this system of equations:

$$
3x+10y=115
$$

$$
11x+4y=95
$$

We can use the transformation rules to eliminate the $x$ variable and isolate the $y$ variable. We will use $R_1$ to denote the first equation and $R_2$ to denote the second. The first equation remains unchanged, and the second is transformed to:

$$
11R_1+(-3)R_2\rightarrow R_2
$$

This results in the transformation of $R_2$ to:

$$
98y=980
$$

$$
y=10
$$

We can now substitute 10 for $y$ in our first equation and calculate for $x$:

$$
x=5
$$
